Prompt 4:

Considering natural and artificial intelligence, note that these categories are not necessarily mutually exclusive. In fact they are necessarily mutually inclusive! Disambiguating "artificial" from "human" is made difficult by that artificial generally means 'emerging from a causal chain which necessarily includes humans.' AI generally entails the human use of programming language(s) to precisely describe both a search space of possible algorithms, and a meta-algorithm to traverse the space until a sufficient candidate algorithm is found.
So, while human intelligence is not artificial, artificial intelligence remains human (if the term is at all accurate), and the AI programs in our lab are no exception. 

In analyzing artificial intelligence, we can examine the artifact as a black box, but--as we learned in "Could a Neuroscientist Understand a Microprocessor"--we might end up learning less about what's in the box and more about ourselves. Critically, sometimes we can just look directly in the box. From the perspective of the lab student, for each puzzle, a human solved it and then the computer solved it in a different way. From the perspective of the instructor, a student solves the problem, then the instructor solves the problem with a computer. The latter perspective is not necessarily "more correct" than simply saying that "a computer did it," but it is nevertheless in a sense more complete. 

I'm not an instructor, so to attain this deeper understanding I had to dig in myself. First I attempted in real time a Prolog solution to solve Towers of Hanoi using the methodology of the river crossing. This is a naive depth first search, with a named symbol for each disk. The relative presence/absence of human intelligence in artificial intelligence solutions becomes readily apparent in the elegance of the provided solution in comparison to my naive approach. Prolog's AI mantle has already been challenged in the accusation that it is "just a domain specific language for depth first search," but the provided ToH solution is very clearly "just a recursive algorithm." This is the optimal recording of the recursive strategy that some human players seemed to be subconsiously using. In he provided solution, the meaningful algorithm search has already been completely solved the human by the time they sit down to write the program. As what is left undone by the human is accomplished by the machine, one could argue that comparatively there is more "machine intelligence" summoned by the running of of my not-very-human-intelligent solution. 

Second, I needed to understand Prof Bang's 15-puzzle heuristic search demo, and I can't be sure that I really understand an algorithm until I implement it myself, so (for fun) I did! More tradeoff analysis to follow.

Third, I also implemented a value-iteration approach to the 15-puzzle. I think Prof Agarwal called what we learned in class q-learning? But in this case transition dynamics are deterministic, so maybe it's value-iteration? In either case, I haven't done it before, and I didn't feel that I had a solid grasp, so for fun and learning, I wrote my own implementation. Dynamic programming is the most similar to modern machine learning of the methods covered here, and if human and artificial intelligence were of a dichotomous nature, we would expect this approach to seem the least human.

This response is about the nature of intelligence, not performance analysis, so I will stick to only the relevant details. 1/2 of possible tile arrangements are solvable game states. There are 16!/2=10,461,394,944,000 game states, representable each in a minimum of log2(16!/2)= 43 bits, so we need a minimum of 54 terabytes of information to enumerate the bare game states alone, under an ideal 43 bit word-size (anyone know where I can get a 43 bit computer?). This is prior to the association of any metadata which could be used to solve the problem. Clearly this is intractable, so we need to break this down into smaller problems. I don't know enough combinatorics, so I just tried solving the first tile, then the second, third, fourth, etc., each without disturbing the solved pieces, just like I did solving by hand. Anyone who has tried this by hand knows you will eventually back yourself into an unsolvable subproblem, at which point you need to move an already solved tile. I wasn't sure of a smart way to guarantee fallback to termination, so I looked if anyone had tried this already. Someone had (paper linked)! If a block is reach solving the nth through mth tiles, they simply free up the (n-1)th tile. Genius! In the worst theoretical case, you would fall back to solving nearly the entire board and exhaust computational resources of your machine, but in all likelihood you will find a solvable subproblem much sooner. This solution nearly always finds a solution with fewer than 160 steps, so is about half as performant as the optimal solution, not bad! 

So what do we learn? Limitations on (the development of) AI:
Generalizing as modestly as possible--in the real world of AI when algorithm designers run up against constraints in existing capabilities of machines and machine intelligence, they have no other points of reference but themselves, so the meta-algorithms of artificial intelligence can wind up looking awfully human! Again--bitter lesson--this probably isn't a good thing.

What about computational efficiency?
I spent all this time hacking together value-iteration, but in a sense heuristic search with its average of >60k steps is better. Value iteration takes about 2 seconds on average (training + execution), while heuristic search takes 20ms. It's not thinking about much trying to preserve steps or problem decomposition, it's just going. Bitter lesson.

In theory, we could study a human to identify and approximate their algorithm to be run close to this fast or even faster, but I don't actually believe it is hand-speed alone that keeps my manual puzzle solving ability on the scale of minutes. There is a lot of pattern recognition hardware that I simply cannot shut off, and just like with value-iteration, most of the computational effort probably does not immediately present itself as a move, and I'm probably doing a lot more of it than is exposed to my conscious awareness!

Note on value-iteration:
I think optimality conditions are also met by my 15-puzzle heuristics for A*? But we already were skeptical of Prolog's depth first search being constitutive of AI, so that's definitely cheating. On the other hand, value-iteration is real AI... or is it? Setting a discount factor of 1, each iteration propagates its reward to all directly reachable states, and if we are smart we will stop as soon as a non-zero value reaches the present game state. Sounds a lot like breadth first search! In this case, the value function following n iterations is exactly identical to a sparse encoding of the game's state adjacency matrix plus the identity and raised to the nth power. This literally is A*, but with an "all roads lead to Rome but prefer optionality" heuristic. Again we look under the hood of AI and find good ol' traditional search.


Solving the 15-puzzle using local value-iteration: https://mediatum.ub.tum.de/doc/1283911/60434.pdf
Could a Neuroscientist Understand a Microprocessor: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5230747/
